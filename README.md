### Understanding Innovation Quality with Large-Language Models
Unstructured textual information is important for understanding innovation but chal-
lenging to study. The advent of large-language models (LLMs) relieves this constraint.
This paper develops deep-learning predictive models incorporating ChatGPT textual
embeddings to access intricate information about patent quality. These models achieve
an R-squared score of 42% predicting patent value and improve the identification of the
worst and best applications by 10 percentage points. Using patent value captured by
the LLMs, a long-short portfolio generates 6.6% yearly abnormal returns. The models
also enable a novel, richer measure of patent value, accounting for potential institutional
anticipation. Furthermore, LLMs provide an opportunity to enhance corporate policy
vis-Ã -vis patenting, including revising applications, which could flatten differences in
skill across firms and lawyers. Such techniques improve writing but not technological
quality-two orthogonal components isolated through a novel decomposition. Both significantly drive patent acceptance yet affect different dimensions of later patent and firm outcomes.